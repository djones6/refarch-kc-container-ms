{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c1c07ef50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(99)\n",
    "torch.manual_seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "races_to_consider = [0,4]\n",
    "unprivileged_groups = [{'race': 4.0}]\n",
    "privileged_groups = [{'race': 0.0}]\n",
    "favorable_label = 0.0 \n",
    "unfavorable_label = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = '/Users/shilpibhattacharyya/Downloads/UTKFace/'\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: /Users/shilpibhattacharyya/Downloads/UTKFace/39_1_20170116174525125.jpg.chip.jpg\n",
      "Missing: /Users/shilpibhattacharyya/Downloads/UTKFace/61_1_20170109150557335.jpg.chip.jpg\n",
      "Missing: /Users/shilpibhattacharyya/Downloads/UTKFace/61_1_20170109142408075.jpg.chip.jpg\n"
     ]
    }
   ],
   "source": [
    "protected_race = []\n",
    "outcome_gender = []\n",
    "feature_image = []\n",
    "feature_age = []\n",
    "\n",
    "for i, image_path in enumerate(glob.glob(image_dir + \"*.jpg\")):\n",
    "    try:\n",
    "        age, gender, race = image_path.split('/')[-1].split(\"_\")[:3]\n",
    "        age = int(age)\n",
    "        gender = int(gender)\n",
    "        race = int(race)\n",
    "        \n",
    "        if race in races_to_consider:\n",
    "            protected_race.append(race)\n",
    "            outcome_gender.append(gender)\n",
    "            feature_image.append(resize(io.imread(image_path), (img_size, img_size)))\n",
    "            feature_age.append(age)\n",
    "    except:\n",
    "        print(\"Missing: \" + image_path)\n",
    "\n",
    "feature_image_mat = np.array(feature_image)\n",
    "outcome_gender_mat =  np.array(outcome_gender)\n",
    "protected_race_mat =  np.array(protected_race)\n",
    "age_mat = np.array(feature_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Input: 128x128 face image (eye aligned).\n",
    "    Output: 1-D tensor with 2 elements. Used for binary classification.\n",
    "    Parameters:\n",
    "        Number of conv layers: 3\n",
    "        Number of fully connected layers: 2       \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ThreeLayerCNN,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,6,5)\n",
    "        self.pool = torch.nn.MaxPool2d(2,2)\n",
    "        self.conv2 = torch.nn.Conv2d(6,16,5)\n",
    "        self.conv3 = torch.nn.Conv2d(16,16,6)\n",
    "        self.fc1 = torch.nn.Linear(16*4*4,120)\n",
    "        self.fc2 = torch.nn.Linear(120,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1,16*4*4)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_image_mat_normed = 2.0 *feature_image_mat.astype('float32') - 1.0\n",
    "\n",
    "N = len(feature_image_mat_normed)\n",
    "ids = np.random.permutation(N)\n",
    "train_size=int(0.7 * N)\n",
    "X_train = feature_image_mat_normed[ids[0:train_size]]\n",
    "y_train = outcome_gender_mat[ids[0:train_size]]\n",
    "X_test = feature_image_mat_normed[ids[train_size:]]\n",
    "y_test = outcome_gender_mat[ids[train_size:]]\n",
    "\n",
    "p_train = protected_race_mat[ids[0:train_size]]\n",
    "p_test = protected_race_mat[ids[train_size:]]\n",
    "\n",
    "age_train = age_mat[ids[0:train_size]]\n",
    "age_test = age_mat[ids[train_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(Variable(torch.FloatTensor(X_train.astype('float32'))), Variable(torch.LongTensor(y_train.astype('float32'))))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test = torch.utils.data.TensorDataset(Variable(torch.FloatTensor(X_test.astype('float32'))), Variable(torch.LongTensor(y_test.astype('float32'))))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 60, 60]             456\n",
      "         MaxPool2d-2            [-1, 6, 30, 30]               0\n",
      "            Conv2d-3           [-1, 16, 26, 26]           2,416\n",
      "         MaxPool2d-4           [-1, 16, 13, 13]               0\n",
      "            Conv2d-5             [-1, 16, 8, 8]           9,232\n",
      "         MaxPool2d-6             [-1, 16, 4, 4]               0\n",
      "            Linear-7                  [-1, 120]          30,840\n",
      "            Linear-8                    [-1, 2]             242\n",
      "================================================================\n",
      "Total params: 43,186\n",
      "Trainable params: 43,186\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.32\n",
      "Params size (MB): 0.16\n",
      "Estimated Total Size (MB): 0.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ThreeLayerCNN().to(device)\n",
    "summary(model, (3,img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/129], Loss: 0.4559\n",
      "Epoch [2/5], Step [100/129], Loss: 0.4887\n",
      "Epoch [3/5], Step [100/129], Loss: 0.2706\n",
      "Epoch [4/5], Step [100/129], Loss: 0.2723\n",
      "Epoch [5/5], Step [100/129], Loss: 0.2519\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "print_freq = 100\n",
    "\n",
    "# Specify the loss and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training the model\n",
    "num_batches = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (idx+1) % print_freq == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, idx+1, num_batches, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on test set in eval mode.\n",
    "model.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred += predicted.tolist()\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataset_wrapper(outcome, protected, unprivileged_groups, privileged_groups,\n",
    "                          favorable_label, unfavorable_label):\n",
    "    \"\"\" A wraper function to create aif360 dataset from outcome and protected in numpy array format.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data=outcome,\n",
    "                      columns=['outcome'])\n",
    "    df['race'] = protected\n",
    "    \n",
    "    dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                       unfavorable_label=unfavorable_label,\n",
    "                                       df=df,\n",
    "                                       label_names=['outcome'],\n",
    "                                       protected_attribute_names=['race'],\n",
    "                                       unprivileged_protected_attributes=unprivileged_groups)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_traning_dataset = dataset_wrapper(outcome=y_train, protected=p_train, \n",
    "                                                 unprivileged_groups=unprivileged_groups, \n",
    "                                                 privileged_groups=privileged_groups,\n",
    "                                                 favorable_label=favorable_label,\n",
    "                                          unfavorable_label=unfavorable_label)\n",
    "original_test_dataset = dataset_wrapper(outcome=y_test, protected=p_test, \n",
    "                                              unprivileged_groups=unprivileged_groups, \n",
    "                                              privileged_groups=privileged_groups,\n",
    "                                                 favorable_label=favorable_label,\n",
    "                                          unfavorable_label=unfavorable_label)\n",
    "plain_predictions_test_dataset = dataset_wrapper(outcome=y_pred, protected=p_test, \n",
    "                                                       unprivileged_groups=unprivileged_groups,\n",
    "                                                       privileged_groups=privileged_groups,\n",
    "                                                 favorable_label=favorable_label,\n",
    "                                          unfavorable_label=unfavorable_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_metric_nodebiasing_test = ClassificationMetric(original_test_dataset, \n",
    "                                                 plain_predictions_test_dataset,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.866610\n",
      "Test set: Balanced classification accuracy = 0.864336\n",
      "Test set: Statistical parity difference = -0.101543\n",
      "Test set: Disparate impact = 0.822329\n",
      "Test set: Equal opportunity difference = -0.083823\n",
      "Test set: Average odds difference = -0.039768\n",
      "Test set: Theil index = 0.085988\n",
      "Test set: False negative rate difference = 0.083823\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_nodebiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "print(\"Test set: False negative rate difference = %f\" % classified_metric_nodebiasing_test.false_negative_rate_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(original_traning_dataset)\n",
    "transf_traning_dataset = RW.transform(original_traning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(original_traning_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "metric_tranf_train = BinaryLabelDatasetMetric(transf_traning_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between privileged and unprivileged groups = -0.096604\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between privileged and unprivileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between privileged and unprivileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between privileged and unprivileged groups = %f\" % metric_tranf_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original testing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between privileged and unprivileged groups = -0.087639\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Transformed testing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between privileged and unprivileged groups = 0.008971\n"
     ]
    }
   ],
   "source": [
    "metric_orig_test = BinaryLabelDatasetMetric(original_test_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "transf_test_dataset = RW.transform(original_test_dataset)\n",
    "metric_transf_test = BinaryLabelDatasetMetric(transf_test_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original testing dataset\"))\n",
    "print(\"Difference in mean outcomes between privileged and unprivileged groups = %f\" % metric_orig_test.mean_difference())\n",
    "display(Markdown(\"#### Transformed testing dataset\"))\n",
    "print(\"Difference in mean outcomes between privileged and unprivileged groups = %f\" % metric_transf_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranf_train = torch.utils.data.TensorDataset(Variable(torch.FloatTensor(X_train.astype('float32'))),\n",
    "                                             Variable(torch.LongTensor(transf_traning_dataset.labels.astype('float32'))),\n",
    "                                            Variable(torch.FloatTensor(transf_traning_dataset.instance_weights.astype('float32'))),)\n",
    "tranf_train_loader = torch.utils.data.DataLoader(tranf_train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceWeighetedCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"Cross entropy loss with instance weights.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(InstanceWeighetedCrossEntropyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, target, weights):\n",
    "        loss = log_sum_exp(logits) - select_target_class(logits, target.squeeze(1))\n",
    "        loss = loss * weights\n",
    "        return loss.mean()\n",
    "\n",
    "#Helper functions\n",
    "def select_target_class(logits, target):\n",
    "    batch_size, num_classes = logits.size()\n",
    "    mask = torch.autograd.Variable(torch.arange(0, num_classes)\n",
    "                                               .long()\n",
    "                                               .repeat(batch_size, 1)\n",
    "                                               .to(device)\n",
    "                                               .eq(target.data.repeat(num_classes, 1).t()))\n",
    "    return logits.masked_select(mask)\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    c, _ = torch.max(x, 1)\n",
    "    y = c + torch.log(torch.exp(x - c.unsqueeze(dim=1).expand_as(x)).sum(1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranf_model = ThreeLayerCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/129], Loss: 0.5977\n",
      "Epoch [2/5], Step [100/129], Loss: 0.4117\n",
      "Epoch [3/5], Step [100/129], Loss: 0.3861\n",
      "Epoch [4/5], Step [100/129], Loss: 0.3440\n",
      "Epoch [5/5], Step [100/129], Loss: 0.2706\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "print_freq = 100\n",
    "\n",
    "# Specify the loss and the optimizer\n",
    "criterion = InstanceWeighetedCrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tranf_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training the new model\n",
    "num_batches = len(tranf_train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (images, labels, weights) in enumerate(tranf_train_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = tranf_model(images)\n",
    "        loss = criterion(outputs, labels, weights)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (idx+1) % print_freq == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, idx+1, num_batches, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "tranf_model.eval()\n",
    "y_pred_transf = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = tranf_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred_transf += predicted.tolist()\n",
    "y_pred_transf = np.array(y_pred_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_predictions_test_dataset = dataset_wrapper(outcome=y_pred_transf, protected=p_test, \n",
    "                                                  unprivileged_groups=unprivileged_groups,\n",
    "                                                  privileged_groups=privileged_groups,\n",
    "                                                 favorable_label=favorable_label,\n",
    "                                                  unfavorable_label=unfavorable_label\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_metric_debiasing_test = ClassificationMetric(original_test_dataset, \n",
    "                                                 transf_predictions_test_dataset,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.866610\n",
      "Test set: Balanced classification accuracy = 0.864336\n",
      "Test set: Statistical parity difference = -0.101543\n",
      "Test set: Disparate impact = 0.822329\n",
      "Test set: Equal opportunity difference = -0.083823\n",
      "Test set: Average odds difference = -0.039768\n",
      "Test set: Theil_index = 0.085988\n",
      "Test set: False negative rate difference = 0.083823\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.848768\n",
      "Test set: Balanced classification accuracy = 0.855244\n",
      "Test set: Statistical parity difference = -0.115225\n",
      "Test set: Disparate impact = 0.753367\n",
      "Test set: Equal opportunity difference = -0.095048\n",
      "Test set: Average odds difference = -0.054926\n",
      "Test set: Theil_index = 0.140974\n",
      "Test set: False negative rate difference = 0.095048\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_nodebiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "print(\"Test set: False negative rate difference = %f\" % classified_metric_nodebiasing_test.false_negative_rate_difference())\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Statistical parity difference = %f\" % classified_metric_debiasing_test.statistical_parity_difference())\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())\n",
    "print(\"Test set: False negative rate difference = %f\" % classified_metric_debiasing_test.false_negative_rate_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Metrics sliced by age\n",
    "age_range_intervals = [0, 10, 20, 40, 60, 150]\n",
    "nodebiasing_perf = []\n",
    "debiasing_perf = []\n",
    "\n",
    "for idx in range(len(age_range_intervals)-1):\n",
    "    start = age_range_intervals[idx]\n",
    "    end = age_range_intervals[idx+1]\n",
    "    ids = np.where((age_test>start) & (age_test<end))\n",
    "    true_dataset = dataset_wrapper(outcome=y_test[ids], protected=p_test[ids],\n",
    "                                   unprivileged_groups=unprivileged_groups,\n",
    "                                   privileged_groups=privileged_groups,\n",
    "                                   favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label)\n",
    "    transf_pred_dataset = dataset_wrapper(outcome=y_pred_transf[ids], protected=p_test[ids],\n",
    "                                          unprivileged_groups=unprivileged_groups,\n",
    "                                          privileged_groups=privileged_groups,\n",
    "                                          favorable_label=favorable_label,\n",
    "                                          unfavorable_label=unfavorable_label)\n",
    "    pred_dataset = dataset_wrapper(outcome=y_pred[ids], protected=p_test[ids],\n",
    "                                   unprivileged_groups=unprivileged_groups,\n",
    "                                   privileged_groups=privileged_groups,\n",
    "                                   favorable_label=favorable_label,\n",
    "                                   unfavorable_label=unfavorable_label)\n",
    " \n",
    "    classified_metric_nodebiasing_test = ClassificationMetric(true_dataset, \n",
    "                                                 pred_dataset,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    classified_metric_debiasing_test = ClassificationMetric(true_dataset, \n",
    "                                                 transf_pred_dataset,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    nodebiasing_perf.append(classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "    debiasing_perf.append(classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "\n",
    "N = len(age_range_intervals)-1\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(N)\n",
    "width = 0.35\n",
    "p1 = ax.bar(ind, nodebiasing_perf, width, color='r')\n",
    "p2 = ax.bar(ind + width, debiasing_perf, width,\n",
    "            color='y')\n",
    "ax.set_title('Equal opportunity difference by age group')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels([str(age_range_intervals[idx])+'-'+str(age_range_intervals[idx+1]) for idx in range(N)])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('Before', 'After'))\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
